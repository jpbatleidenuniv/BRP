{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open cluster cataloging\n",
    "##### In this notebook we study the discrepancies between various (open) cluster catalogues. We use the open cluster catalogue by Hunt & Reffert (2023) as reference cluster and we base our results under the assumptions that the catalogue concerned, achieved the most accurate and precise data for the open clusters in question.\n",
    "\n",
    "First we start by creating a datahandler made to get tables from the catalogues in question. We crossmatch the literature with the crossmatch table by Hunt & Reffert (2023). We then see if any of those crossmatched clusters occur in the original literature data. The clusters in the literature can be in one of two states which yields respective data tables:\n",
    "- Matched = The clusters from the literature is confirmed by the Hunt-catalogue\n",
    "  - Out of $N$ literature clusters $C$ Hunt-clusters are confirmed which yields $C$ records in the literature-and Hunt-catalogue (I and II in the code)\n",
    "- Not Matched = The clusters from the literature is not confirmed\n",
    "  - Out of $N$ literature clusters $N-C$ literature clusters are refuted which yields $N-C$ records in the literature catalogue (III in the code) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "cantat = pd.read_csv('Data\\\\CantatGaudin\\\\cantatgaudinfile.csv')\n",
    "hunt = pd.read_csv('Data\\\\Hunt\\\\huntfile.csv')\n",
    "xmatch = pd.read_csv('Data\\\\Hunt\\\\xmatchfile.csv').dropna(subset='Sep')\n",
    "khar = pd.read_csv('Data\\\\Kharchenko\\\\kharchenkofile.csv').query('Type != \"g\"')\n",
    "dias = pd.read_csv('Data\\\\Dias\\\\diasfile.csv')\n",
    "dias['Cluster'] = dias['Cluster'].str.replace(' ', '_').str.replace('-', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datahandler(df_lit, df=hunt, crossmatch=xmatch):\n",
    "\n",
    "    if df_lit is cantat:\n",
    "        sourcecat = 'Cantat-Gaudin+20'\n",
    "        NameCol = 'Cluster'\n",
    "    elif df_lit is khar:\n",
    "        sourcecat = 'Kharchenko+13'\n",
    "        NameCol = 'Name'\n",
    "    elif df_lit is dias:\n",
    "        sourcecat = 'Dias+02'\n",
    "        NameCol = 'Cluster'\n",
    "        # df_lit['Cluster'] = df_lit['Cluster'].str.replace(' ', '_').str.replace('-', '_')\n",
    "        # df_lit.drop_duplicates(subset=['Cluster'])\n",
    "\n",
    "    df = df.query('Type == \"o\"') #Only open clusters\n",
    "    crossmatch = crossmatch.query('SourceCat == @sourcecat').drop_duplicates('ID')\n",
    "\n",
    "    xm = pd.merge(crossmatch, df, on='ID', how='inner') #Crossmatched clusters\n",
    "    allnames = xm.assign(synonym = xm['AllNames'].str.split(',')).explode('synonym').add_suffix('_h') #Create AllNames column with synonyms of the OCs\n",
    "    \n",
    "    # if df_lit is dias:\n",
    "    #     allnames['synonym_h'] = allnames['synonym_h'].str.replace('-', '_').str.replace(' ', '_')\n",
    "    \n",
    "    df_matched = pd.merge(df_lit, allnames, left_on=NameCol, right_on='synonym_h', how='outer', indicator=True).drop_duplicates(NameCol) #Crossmatched clusters (matched with literature)\n",
    "    \n",
    "    matched = df_matched.query('_merge == \"both\"') #Matched clusters\n",
    "    not_matched = df_matched.query('_merge == \"left_only\"')\n",
    "    \n",
    "    hunt_matched = matched.filter(regex='_h$').drop(columns=['synonym_h'])\n",
    "    lit_matched = matched[df_lit.columns]\n",
    "    lit_not_matched = not_matched[df_lit.columns]\n",
    "    \n",
    "    return hunt_matched, lit_matched, lit_not_matched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantat matched: 1427, Cantat not matched: 54, Cantat total: 1481\n",
      "Kharchenko matched: 1391, Kharchenko not matched: 1468, Kharchenko total: 2859\n",
      "Dias matched: 1167, Dias not matched: 999, Dias total: 2167\n"
     ]
    }
   ],
   "source": [
    "cantat_matched, cantat_lit, cantat_not_matched = datahandler(cantat)\n",
    "khar_matched, khar_lit, khar_not_matched = datahandler(khar)\n",
    "dias_matched, dias_lit, dias_not_matched = datahandler(dias)\n",
    "\n",
    "print(f'Cantat matched: {cantat_matched.shape[0]}, Cantat not matched: {cantat_not_matched.shape[0]}, Cantat total: {cantat.shape[0]}')\n",
    "print(f'Kharchenko matched: {khar_matched.shape[0]}, Kharchenko not matched: {khar_not_matched.shape[0]}, Kharchenko total: {khar.shape[0]}')\n",
    "print(f'Dias matched: {dias_matched.shape[0]}, Dias not matched: {dias_not_matched.shape[0]}, Dias total: {dias.shape[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing\n",
    "Now that the relavant clusters have been selected from the literature and the Hunt-catalogue. Several techniques will be employed into researching what properties make the clusters belong to the \"real\" data. Or the opposite, what makes clusters pop up in the literature but not with Gaia DR3\n",
    "\n",
    "We will take on several avenues into qualifying these discrepancies\n",
    "- Correlation matrices\n",
    "- Minimum Spanning Trees / Hierarchical Clustering\n",
    "- Binary classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
